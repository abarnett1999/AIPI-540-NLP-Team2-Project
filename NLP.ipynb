{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abarnett1999/AIPI-540-NLP-Team2-Project/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification using Word Counts / TFIDF"
      ],
      "metadata": {
        "id": "zgpxAEjGAO4B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYGERzmB813E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21b7a219-0c77-4e4d-d450-05b87179d2a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import time\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from tqdm import tqdm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "#!python -m spacy download en_core_web_md\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score"
      ],
      "metadata": {
        "id": "4izBBYc1GByB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Prepare Data**"
      ],
      "metadata": {
        "id": "qLo8eGyEAjva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from csv to pandas dataframe\n",
        "data_df = pd.read_csv('labeled_data.csv')\n",
        "\n",
        "# Clean it up a bit more \n",
        "data_df = data_df[['filename', 'impression', 'label']]"
      ],
      "metadata": {
        "id": "8p1B7uY6C-GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df"
      ],
      "metadata": {
        "id": "RdwyMAktEMnF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "1daff8dd-55a8-42ba-bba5-22794eed9f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     filename                                         impression  label\n",
              "0       1.xml                               Normal chest x-XXXX.      0\n",
              "1      10.xml                  No acute cardiopulmonary process.      0\n",
              "2     100.xml                                 No active disease.      0\n",
              "3    1000.xml   Increased opacity in the right upper lobe wit...      1\n",
              "4    1001.xml  Diffuse fibrosis. No visible focal acute disease.      1\n",
              "..        ...                                                ...    ...\n",
              "410  1377.xml     No acute radiographic cardiopulmonary process.      0\n",
              "411  1378.xml                    Negative for acute abnormality.      0\n",
              "412  1379.xml                 No acute cardiopulmonary findings.      0\n",
              "413   138.xml                    No acute preoperative findings.      0\n",
              "414  1380.xml              No acute cardiopulmonary abnormality.      0\n",
              "\n",
              "[415 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3a28bdf-5cf8-4954-a5f7-713e4096233b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>impression</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.xml</td>\n",
              "      <td>Normal chest x-XXXX.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10.xml</td>\n",
              "      <td>No acute cardiopulmonary process.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100.xml</td>\n",
              "      <td>No active disease.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000.xml</td>\n",
              "      <td>Increased opacity in the right upper lobe wit...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1001.xml</td>\n",
              "      <td>Diffuse fibrosis. No visible focal acute disease.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>1377.xml</td>\n",
              "      <td>No acute radiographic cardiopulmonary process.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>1378.xml</td>\n",
              "      <td>Negative for acute abnormality.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>412</th>\n",
              "      <td>1379.xml</td>\n",
              "      <td>No acute cardiopulmonary findings.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>138.xml</td>\n",
              "      <td>No acute preoperative findings.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>1380.xml</td>\n",
              "      <td>No acute cardiopulmonary abnormality.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>415 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3a28bdf-5cf8-4954-a5f7-713e4096233b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3a28bdf-5cf8-4954-a5f7-713e4096233b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3a28bdf-5cf8-4954-a5f7-713e4096233b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and test sets - 80/20\n",
        "X = data_df['impression']\n",
        "y = data_df['label']\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y, random_state=0,test_size=0.2)"
      ],
      "metadata": {
        "id": "wkDv72nCF0H8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pipeline to Streamlit**"
      ],
      "metadata": {
        "id": "zj6K5pWbBnqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.pipelines import make_pipeline\n",
        "\n",
        "# #The pipeline will save all transformations and weights to make predictions \n",
        "# #easier. The pipeline can be saved out and reused easily.\n",
        "# pipeline = make_pipeline([\n",
        "#           tokenize(), # <--- This needs the sklearn TransformerMixin or something similar \n",
        "#           TfidfVectorizer(),\n",
        "#           LogisticRegression(solver = \"saga\")\n",
        "# ])\n",
        "\n",
        "# pipeline.fit(Xtrain, ytrain)\n",
        "# pipeline.predict(Xtest)"
      ],
      "metadata": {
        "id": "cAQIoPIFteFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Pre-process text**"
      ],
      "metadata": {
        "id": "GpezquMZHZ3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize text on white space and punctuation (using NLTK)\n",
        "# Then lemmatize the text \n",
        "\n",
        "def tokenize(sentence,method):\n",
        "# Tokenize and lemmatize text, remove stopwords and punctuation\n",
        "\n",
        "    punctuations = string.punctuation\n",
        "    stopwords = list(STOP_WORDS)\n",
        "\n",
        "    if method=='nltk':\n",
        "        # Tokenize\n",
        "        tokens = nltk.word_tokenize(sentence,preserve_line=True)\n",
        "        # Remove stopwords and punctuation\n",
        "        tokens = [word for word in tokens if word not in stopwords and word not in punctuations]\n",
        "        # Lemmatize\n",
        "        wordnet_lemmatizer = WordNetLemmatizer()\n",
        "        tokens = [wordnet_lemmatizer.lemmatize(word) for word in tokens]\n",
        "        tokens = \" \".join([i for i in tokens])\n",
        "    else:\n",
        "        # Tokenize\n",
        "        with nlp.select_pipes(enable=['tokenizer','lemmatizer']):\n",
        "            tokens = nlp(sentence)\n",
        "        # Lemmatize\n",
        "        tokens = [word.lemma_.lower().strip() for word in tokens]\n",
        "        # Remove stopwords and punctuation\n",
        "        tokens = [word for word in tokens if word not in stopwords and word not in punctuations]\n",
        "        tokens = \" \".join([i for i in tokens])\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "7jHHwedsGWjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the training set \n",
        "tqdm.pandas()\n",
        "X_train_processed = X_train.progress_apply(lambda x: tokenize(x,method='nltk'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymKlbXH7H6ma",
        "outputId": "20a2e949-3a5a-405a-ff20-afd5193b48dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 332/332 [00:04<00:00, 69.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the test set text\n",
        "tqdm.pandas()\n",
        "X_test_processed = X_test.progress_apply(lambda x: tokenize(x,method='nltk'))"
      ],
      "metadata": {
        "id": "e7cDtapTNYZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c133ff8b-0a55-4527-daa1-af2e38a339a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83/83 [00:00<00:00, 1114.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create features**"
      ],
      "metadata": {
        "id": "12XdhaoWT28E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_features(train_data, test_data, ngram_range, method):\n",
        "    if method == 'tfidf':\n",
        "        # Create features using TFIDF\n",
        "        vec = TfidfVectorizer(ngram_range=ngram_range)\n",
        "        X_train = vec.fit_transform(train_data)\n",
        "        X_test = vec.transform(test_data)\n",
        "\n",
        "    elif method=='count':\n",
        "        # Create features using word counts\n",
        "        vec = CountVectorizer(ngram_range=ngram_range)\n",
        "        X_train = vec.fit_transform(train_data)\n",
        "        X_test = vec.transform(test_data)\n",
        "\n",
        "    return X_train, X_test"
      ],
      "metadata": {
        "id": "IBj5XWy4T8rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Option 1: Count Vectorization**"
      ],
      "metadata": {
        "id": "UV5PxzLTV-kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Option 1: Create features using count vectorization\n",
        "\n",
        "method = 'count'\n",
        "ngram_range = (1, 2)\n",
        "X_train,X_test = build_features(X_train_processed,X_test_processed,ngram_range,method)"
      ],
      "metadata": {
        "id": "k53FP3iMUjpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5BsrHD3VMNk",
        "outputId": "c660b717-3b80-469c-d714-3db79156ee8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<332x1998 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 5460 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train model - Count Vectorization**"
      ],
      "metadata": {
        "id": "sYDi4KtzUD1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple softmax regression classification model \n",
        "\n",
        "# Train on training set \n",
        "logreg_model = LogisticRegression(solver='saga')\n",
        "logreg_model.fit(X_train,y_train)\n",
        "preds = logreg_model.predict(X_train)\n",
        "acc = sum(preds==y_train)/len(y_train)\n",
        "recall = recall_score(y_train, preds)\n",
        "print('Accuracy on the training set is {:.3f}'.format(acc))\n",
        "print('Recall on the training set is {:.3f}'.format(recall))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxssbCpWVWTF",
        "outputId": "aeac50df-cd80-46f8-83bd-c6b01e2a70fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the training set is 0.988\n",
            "Recall on the training set is 0.974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model on test set \n",
        "\n",
        "test_preds = logreg_model.predict(X_test)\n",
        "test_acc = sum(test_preds==y_test)/len(y_test)\n",
        "test_recall = recall_score(y_test, test_preds)\n",
        "print('Accuracy on the test set is {:.3f}'.format(test_acc))\n",
        "print('Recall on the test set is {:.3f}'.format(test_recall))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO_6_j1jVigv",
        "outputId": "7dd94534-12b0-4ff0-d2e9-d6164a43102f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the test set is 0.916\n",
            "Recall on the test set is 0.917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8RpHUVtFWRmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Option 2: TFIDF**"
      ],
      "metadata": {
        "id": "Rl9GX-0hWctU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Option 2: Create features using TFIDF\n",
        "\n",
        "method = 'tfidf'\n",
        "ngram_range = (1, 2)\n",
        "X_train,X_test = build_features(X_train_processed,X_test_processed,ngram_range,method)"
      ],
      "metadata": {
        "id": "xhzyMwztWctV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b706352-8ff7-476e-93f5-24641c9531fa",
        "id": "n8DnzDarWctW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<332x1998 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 5460 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train model - TFIDF**"
      ],
      "metadata": {
        "id": "rK35Q4ATWctY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple softmax regression classification model \n",
        "\n",
        "# Train on training set \n",
        "logreg_model = LogisticRegression(solver='saga')\n",
        "logreg_model.fit(X_train,y_train)\n",
        "preds = logreg_model.predict(X_train)\n",
        "acc = sum(preds==y_train)/len(y_train)\n",
        "recall = recall_score(y_train, preds)\n",
        "print('Accuracy on the training set is {:.3f}'.format(acc))\n",
        "print('Recall on the training set is {:.3f}'.format(recall))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ededc645-6835-4473-b38d-97dfbcac1e0a",
        "id": "bVxMxJoeWctY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the training set is 0.961\n",
            "Recall on the training set is 0.915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model on test set \n",
        "\n",
        "test_preds = logreg_model.predict(X_test)\n",
        "test_acc = sum(test_preds==y_test)/len(y_test)\n",
        "test_recall = recall_score(y_test, test_preds)\n",
        "print('Accuracy on the test set is {:.3f}'.format(test_acc))\n",
        "print('Recall on the test set is {:.3f}'.format(test_recall))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2cf4f23-a328-435a-c69f-ceec012f19a0",
        "id": "87MtlSPZWctc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the test set is 0.916\n",
            "Recall on the test set is 0.875\n"
          ]
        }
      ]
    }
  ]
}