# -*- coding: utf-8 -*-
"""NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19w0O3AaUdun2sDzpwfwHHQJ0JnBLRrBl

## Classification using Word Counts / TFIDF
"""

import os
import numpy as np
import pandas as pd
import string
import time
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from tqdm import tqdm
from sklearn.linear_model import LogisticRegression
import spacy
from spacy.lang.en.stop_words import STOP_WORDS
from spacy.lang.en import English
import nltk
from nltk.stem import WordNetLemmatizer
import warnings
from sklearn.model_selection import train_test_split
from sklearn.metrics import recall_score
nlp = spacy.load('en_core_web_sm')
nltk.download('omw-1.4')
nltk.download('wordnet')
warnings.filterwarnings('ignore')



"""### **Prepare Data**"""

# Load data from csv to pandas dataframe
data_df = pd.read_csv('labeled_data.csv')

# Clean data up a bit more
data_df = data_df[['filename', 'impression', 'label']]

# Split into training and test sets - 80/20
X = data_df['impression']
y = data_df['label']
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)

"""### **Pre-process text**"""


# Tokenize text on white space and punctuation (using NLTK)
# Then lemmatize the text 

def tokenize(sentence, method):
    # Tokenize and lemmatize text, remove stopwords and punctuation

    punctuations = string.punctuation
    stopwords = list(STOP_WORDS)

    if method == 'nltk':
        # Tokenize
        tokens = nltk.word_tokenize(sentence, preserve_line=True)
        # Remove stopwords and punctuation
        tokens = [word for word in tokens if word not in stopwords and word not in punctuations]
        # Lemmatize
        wordnet_lemmatizer = WordNetLemmatizer()
        tokens = [wordnet_lemmatizer.lemmatize(word) for word in tokens]
        tokens = " ".join([i for i in tokens])
    else:
        # Tokenize
        with nlp.select_pipes(enable=['tokenizer', 'lemmatizer']):
            tokens = nlp(sentence)
        # Lemmatize
        tokens = [word.lemma_.lower().strip() for word in tokens]
        # Remove stopwords and punctuation
        tokens = [word for word in tokens if word not in stopwords and word not in punctuations]
        tokens = " ".join([i for i in tokens])
    return tokens


# Process the training set
tqdm.pandas()
X_train_processed = X_train.progress_apply(lambda x: tokenize(x, method='nltk'))

# Process the test set text
tqdm.pandas()
X_test_processed = X_test.progress_apply(lambda x: tokenize(x, method='nltk'))


"""## **Create features**"""
def build_features(train_data, test_data, ngram_range, method):
    if method == 'tfidf':
        # Create features using TFIDF
        vec = TfidfVectorizer(ngram_range=ngram_range)
        X_train = vec.fit_transform(train_data)
        X_test = vec.transform(test_data)

    elif method == 'count':
        # Create features using word counts
        vec = CountVectorizer(ngram_range=ngram_range)
        X_train = vec.fit_transform(train_data)
        X_test = vec.transform(test_data)

    return X_train, X_test


"""#### **Option 1: Count Vectorization**"""

# Option 1: Create features using count vectorization

method = 'count'
ngram_range = (1, 2)
X_train, X_test = build_features(X_train_processed, X_test_processed, ngram_range, method)


"""### **Train model - Count Vectorization**"""

# Simple softmax regression classification model 

# Train on training set 
logreg_model = LogisticRegression(solver='saga')
logreg_model.fit(X_train, y_train)
preds = logreg_model.predict(X_train)
acc = sum(preds == y_train) / len(y_train)
recall = recall_score(y_train, preds)
print('Accuracy on the training set is {:.3f}'.format(acc))
print('Recall on the training set is {:.3f}'.format(recall))

# Evaluate model on test set 

test_preds = logreg_model.predict(X_test)
test_acc = sum(test_preds == y_test) / len(y_test)
test_recall = recall_score(y_test, test_preds)
print('Accuracy on the test set is {:.3f}'.format(test_acc))
print('Recall on the test set is {:.3f}'.format(test_recall))

"""#### **Option 2: TFIDF**"""

# Option 2: Create features using TFIDF

method = 'tfidf'
ngram_range = (1, 2)
X_train, X_test = build_features(X_train_processed, X_test_processed, ngram_range, method)

X_train

"""### **Train model - TFIDF**"""

# Simple softmax regression classification model 

# Train on training set 
logreg_model = LogisticRegression(solver='saga')
logreg_model.fit(X_train, y_train)
preds = logreg_model.predict(X_train)
acc = sum(preds == y_train) / len(y_train)
recall = recall_score(y_train, preds)
print('Accuracy on the training set is {:.3f}'.format(acc))
print('Recall on the training set is {:.3f}'.format(recall))

# Evaluate model on test set 

test_preds = logreg_model.predict(X_test)
test_acc = sum(test_preds == y_test) / len(y_test)
test_recall = recall_score(y_test, test_preds)
print('Accuracy on the test set is {:.3f}'.format(test_acc))
print('Recall on the test set is {:.3f}'.format(test_recall))
